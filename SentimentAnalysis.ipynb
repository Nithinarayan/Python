{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/nNJP9vqUgZJzNiHdmuGE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nithinarayan/Python/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a4pO_noKdLAp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "923fc2c1-7da3-4048-f3e4-32d99938e9f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a302dd3d-c619-4a25-8262-90c38d2d11cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a302dd3d-c619-4a25-8262-90c38d2d11cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving twitter_training.csv to twitter_training.csv\n",
            "Dataset loaded successfully!\n",
            "Shape: (74681, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   2401  Borderlands  Positive  \\\n",
              "0  2401  Borderlands  Positive   \n",
              "1  2401  Borderlands  Positive   \n",
              "2  2401  Borderlands  Positive   \n",
              "3  2401  Borderlands  Positive   \n",
              "4  2401  Borderlands  Positive   \n",
              "\n",
              "  im getting on borderlands and i will murder you all ,  \n",
              "0  I am coming to the borders and I will kill you...     \n",
              "1  im getting on borderlands and i will kill you ...     \n",
              "2  im coming on borderlands and i will murder you...     \n",
              "3  im getting on borderlands 2 and i will murder ...     \n",
              "4  im getting into borderlands and i can murder y...     "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90e028ca-e0fb-4ceb-81a9-5e2fd5de7065\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2401</th>\n",
              "      <th>Borderlands</th>\n",
              "      <th>Positive</th>\n",
              "      <th>im getting on borderlands and i will murder you all ,</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e028ca-e0fb-4ceb-81a9-5e2fd5de7065')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90e028ca-e0fb-4ceb-81a9-5e2fd5de7065 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90e028ca-e0fb-4ceb-81a9-5e2fd5de7065');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4b0aa4df-1050-455c-aeec-22263218bb4b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b0aa4df-1050-455c-aeec-22263218bb4b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4b0aa4df-1050-455c-aeec-22263218bb4b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74681,\n  \"fields\": [\n    {\n      \"column\": \"2401\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3740,\n        \"min\": 1,\n        \"max\": 13200,\n        \"num_unique_values\": 12447,\n        \"samples\": [\n          1616,\n          2660,\n          2335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Borderlands\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Cyberpunk2077\",\n          \"Microsoft\",\n          \"TomClancysRainbowSix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Positive\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Neutral\",\n          \"Irrelevant\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"im getting on borderlands and i will murder you all ,\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 69490,\n        \"samples\": [\n          \"so how does my stained glass open facebook account girl already have 200 likes!!!! and i sure am so!!??? oh thankful!??!?!\",\n          \"How not to get bored about every damn thing in life.\",\n          \"The Best Perfect Way to Protect All the Planet Samsung Galaxy Note10 + By buff. ly / The 2zkjIhU..\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# If you are uploading manually in Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # Upload your CSV file\n",
        "\n",
        "# Replace the filename if needed\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: Step 2 - Data Cleaning (missing values, duplicates, text cleaning)\n",
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "\n",
        "# --- CSV path options ---\n",
        "# Option A (recommended): upload in Colab via files.upload() and set df accordingly\n",
        "# Option B: use existing path from your session (developer-provided path)\n",
        "default_session_path = \"/content/twitter_training.csv\"  # existing path from your session\n",
        "\n",
        "# If you uploaded a file via Colab UI, set uploaded_filename below to the name shown after upload.\n",
        "uploaded_filename = None  # e.g., \"twitter_training.csv\" if you used files.upload()\n",
        "\n",
        "# Load dataframe (try uploaded file first, then fallback to session path)\n",
        "if uploaded_filename:\n",
        "    csv_path = uploaded_filename\n",
        "else:\n",
        "    csv_path = default_session_path\n",
        "\n",
        "print(\"Loading CSV from:\", csv_path)\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Initial shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# ---------- 1) Detect text column ----------\n",
        "text_candidates = [c for c in df.columns if c.lower() in (\"text\",\"tweet\",\"tweet_text\",\"content\",\"message\",\"tweettext\")]\n",
        "if text_candidates:\n",
        "    text_col = text_candidates[0]\n",
        "else:\n",
        "    # fallback: choose object dtype column with highest average length\n",
        "    obj_cols = [c for c in df.columns if df[c].dtype == object]\n",
        "    if not obj_cols:\n",
        "        raise ValueError(\"No string-like column found to use as text column.\")\n",
        "    avg_len = {c: df[c].astype(str).str.len().mean() for c in obj_cols}\n",
        "    text_col = max(avg_len, key=avg_len.get)\n",
        "\n",
        "print(\"Selected text column:\", text_col)\n",
        "\n",
        "# ---------- 2) Check & handle missing values ----------\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows where the text column is missing (common choice for text models)\n",
        "before = len(df)\n",
        "df = df[df[text_col].notna()].copy()\n",
        "dropped = before - len(df)\n",
        "print(f\"Dropped {dropped} rows with missing {text_col}. New shape: {df.shape}\")\n",
        "\n",
        "# If you want to impute other columns, do it here (example: fillna for metadata)\n",
        "# df['some_meta_col'] = df['some_meta_col'].fillna('unknown')\n",
        "\n",
        "# ---------- 3) Remove duplicates ----------\n",
        "# Try to detect id-like columns and drop duplicates using (id + text) when available\n",
        "id_like = [c for c in df.columns if c.lower() in ('id','tweet_id','tweetid','tweet_id_str')]\n",
        "dup_subset = [text_col] + [c for c in id_like if c in df.columns]\n",
        "dups_before = df.duplicated(subset=dup_subset).sum()\n",
        "if dups_before:\n",
        "    df = df.drop_duplicates(subset=dup_subset).reset_index(drop=True)\n",
        "    print(f\"Removed {dups_before} duplicates using subset {dup_subset}. New shape: {df.shape}\")\n",
        "else:\n",
        "    # fallback: drop duplicates based on text only\n",
        "    dups_text = df.duplicated(subset=[text_col]).sum()\n",
        "    if dups_text:\n",
        "        df = df.drop_duplicates(subset=[text_col]).reset_index(drop=True)\n",
        "        print(f\"Removed {dups_text} duplicates based on text. New shape: {df.shape}\")\n",
        "    else:\n",
        "        print(\"No duplicates detected.\")\n",
        "\n",
        "# ---------- 4) Text cleaning function ----------\n",
        "url_re = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "mention_re = re.compile(r'@\\w+')\n",
        "hashtag_re = re.compile(r'#\\w+')\n",
        "html_re = re.compile(r'<.*?>')\n",
        "special_re = re.compile(r'[^A-Za-z0-9\\s]')    # removes punctuation and many emojis; tweak if you want to keep emojis\n",
        "multi_space_re = re.compile(r'\\s+')\n",
        "\n",
        "def clean_tweet_text(text):\n",
        "    # ensure string\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = url_re.sub(' ', text)\n",
        "    text = mention_re.sub(' ', text)\n",
        "    text = hashtag_re.sub(' ', text)\n",
        "    text = html_re.sub(' ', text)\n",
        "    text = special_re.sub(' ', text)\n",
        "    text = text.lower()\n",
        "    text = multi_space_re.sub(' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to a new column 'cleaned_text'\n",
        "print(\"\\nCleaning text (this may take a moment on large datasets)...\")\n",
        "df['cleaned_text'] = df[text_col].apply(clean_tweet_text)\n",
        "\n",
        "# Show a few examples\n",
        "print(\"\\nSample (original -> cleaned):\")\n",
        "for i, row in df[[text_col, 'cleaned_text']].head(8).iterrows():\n",
        "    print(f\"- ORIGINAL: {row[text_col]}\")\n",
        "    print(f\"  CLEANED : {row['cleaned_text']}\\n\")\n",
        "\n",
        "# ---------- 5) Save a processed sample ----------\n",
        "out_dir = Path(\"/content/data\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "sample_path = out_dir / \"processed_sample.csv\"\n",
        "df[[text_col, 'cleaned_text']].head(200).to_csv(sample_path, index=False)\n",
        "print(\"Saved processed sample to:\", sample_path)\n",
        "\n",
        "# Done - df now contains 'cleaned_text' for downstream preprocessing / tokenization\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Stopwords set\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Choose your preferred normalization method:\n",
        "USE_LEMMATIZATION = False    # set to True to use lemmatizer instead of stemming\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize_and_normalize(text):\n",
        "    # Tokenize (simple split, text is already lowercased)\n",
        "    tokens = text.split()\n",
        "\n",
        "    cleaned_tokens = []\n",
        "    for token in tokens:\n",
        "        # Skip stop words & numeric tokens\n",
        "        if token in stop_words:\n",
        "            continue\n",
        "        if token.isnumeric():\n",
        "            continue\n",
        "\n",
        "        # Apply stemming or lemmatization\n",
        "        if USE_LEMMATIZATION:\n",
        "            token = lemmatizer.lemmatize(token)\n",
        "        else:\n",
        "            token = stemmer.stem(token)\n",
        "\n",
        "        cleaned_tokens.append(token)\n",
        "\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Apply tokenization + normalization\n",
        "df[\"tokens\"] = df[\"cleaned_text\"].apply(tokenize_and_normalize)\n",
        "\n",
        "# Preview\n",
        "df[[\"cleaned_text\", \"tokens\"]].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AL_dzPh9hsff",
        "outputId": "ed9dbb9a-21b1-491a-d319-27a93ab777be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV from: /content/twitter_training.csv\n",
            "Initial shape: (74681, 4)\n",
            "Columns: ['2401', 'Borderlands', 'Positive', 'im getting on borderlands and i will murder you all ,']\n",
            "Selected text column: im getting on borderlands and i will murder you all ,\n",
            "\n",
            "Missing values per column:\n",
            "2401                                                       0\n",
            "Borderlands                                                0\n",
            "Positive                                                   0\n",
            "im getting on borderlands and i will murder you all ,    686\n",
            "dtype: int64\n",
            "Dropped 686 rows with missing im getting on borderlands and i will murder you all ,. New shape: (73995, 4)\n",
            "Removed 4505 duplicates using subset ['im getting on borderlands and i will murder you all ,']. New shape: (69490, 4)\n",
            "\n",
            "Cleaning text (this may take a moment on large datasets)...\n",
            "\n",
            "Sample (original -> cleaned):\n",
            "- ORIGINAL: I am coming to the borders and I will kill you all,\n",
            "  CLEANED : i am coming to the borders and i will kill you all\n",
            "\n",
            "- ORIGINAL: im getting on borderlands and i will kill you all,\n",
            "  CLEANED : im getting on borderlands and i will kill you all\n",
            "\n",
            "- ORIGINAL: im coming on borderlands and i will murder you all,\n",
            "  CLEANED : im coming on borderlands and i will murder you all\n",
            "\n",
            "- ORIGINAL: im getting on borderlands 2 and i will murder you me all,\n",
            "  CLEANED : im getting on borderlands 2 and i will murder you me all\n",
            "\n",
            "- ORIGINAL: im getting into borderlands and i can murder you all,\n",
            "  CLEANED : im getting into borderlands and i can murder you all\n",
            "\n",
            "- ORIGINAL: So I spent a few hours making something for fun. . . If you don't know I am a HUGE @Borderlands fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg\n",
            "  CLEANED : so i spent a few hours making something for fun if you don t know i am a huge fan and maya is one of my favorite characters so i decided to make myself a wallpaper for my pc here is the original image versus the creation i made enjoy pic twitter com mlsi5wf9jg\n",
            "\n",
            "- ORIGINAL: So I spent a couple of hours doing something for fun... If you don't know that I'm a huge @ Borderlands fan and Maya is one of my favorite characters, I decided to make a wallpaper for my PC.. Here's the original picture compared to the creation I made:) Have fun! pic.twitter.com / mLsI5wf9Jg\n",
            "  CLEANED : so i spent a couple of hours doing something for fun if you don t know that i m a huge borderlands fan and maya is one of my favorite characters i decided to make a wallpaper for my pc here s the original picture compared to the creation i made have fun pic twitter com mlsi5wf9jg\n",
            "\n",
            "- ORIGINAL: So I spent a few hours doing something for fun... If you don't know I'm a HUGE @ Borderlands fan and Maya is one of my favorite characters.\n",
            "  CLEANED : so i spent a few hours doing something for fun if you don t know i m a huge borderlands fan and maya is one of my favorite characters\n",
            "\n",
            "Saved processed sample to: /content/data/processed_sample.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        cleaned_text  \\\n",
              "0  i am coming to the borders and i will kill you...   \n",
              "1  im getting on borderlands and i will kill you all   \n",
              "2  im coming on borderlands and i will murder you...   \n",
              "3  im getting on borderlands 2 and i will murder ...   \n",
              "4  im getting into borderlands and i can murder y...   \n",
              "5  so i spent a few hours making something for fu...   \n",
              "6  so i spent a couple of hours doing something f...   \n",
              "7  so i spent a few hours doing something for fun...   \n",
              "8  so i spent a few hours making something for fu...   \n",
              "9  2010 so i spent a few hours making something f...   \n",
              "\n",
              "                                              tokens  \n",
              "0                               [come, border, kill]  \n",
              "1                        [im, get, borderland, kill]  \n",
              "2                     [im, come, borderland, murder]  \n",
              "3                      [im, get, borderland, murder]  \n",
              "4                      [im, get, borderland, murder]  \n",
              "5  [spent, hour, make, someth, fun, know, huge, f...  \n",
              "6  [spent, coupl, hour, someth, fun, know, huge, ...  \n",
              "7  [spent, hour, someth, fun, know, huge, borderl...  \n",
              "8  [spent, hour, make, someth, fun, know, huge, r...  \n",
              "9  [spent, hour, make, someth, fun, know, huge, r...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19a1acf1-edb5-4ada-844d-c488e1cf822e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am coming to the borders and i will kill you...</td>\n",
              "      <td>[come, border, kill]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im getting on borderlands and i will kill you all</td>\n",
              "      <td>[im, get, borderland, kill]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "      <td>[im, come, borderland, murder]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "      <td>[im, get, borderland, murder]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "      <td>[im, get, borderland, murder]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>so i spent a few hours making something for fu...</td>\n",
              "      <td>[spent, hour, make, someth, fun, know, huge, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>so i spent a couple of hours doing something f...</td>\n",
              "      <td>[spent, coupl, hour, someth, fun, know, huge, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>so i spent a few hours doing something for fun...</td>\n",
              "      <td>[spent, hour, someth, fun, know, huge, borderl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>so i spent a few hours making something for fu...</td>\n",
              "      <td>[spent, hour, make, someth, fun, know, huge, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2010 so i spent a few hours making something f...</td>\n",
              "      <td>[spent, hour, make, someth, fun, know, huge, r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19a1acf1-edb5-4ada-844d-c488e1cf822e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19a1acf1-edb5-4ada-844d-c488e1cf822e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19a1acf1-edb5-4ada-844d-c488e1cf822e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-50ad3c0a-2b15-46a5-b772-c31b17e6b3fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50ad3c0a-2b15-46a5-b772-c31b17e6b3fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-50ad3c0a-2b15-46a5-b772-c31b17e6b3fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[[\\\"cleaned_text\\\", \\\"tokens\\\"]]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"so i spent a few hours making something for fun if you don t know i am a huge rhandlerr fan and maya is one of my favorite characters so i decided to make myself a wallpaper for my pc here is the original image versus the creation i made enjoy pic twitter com mlsi5wf9jg\",\n          \"im getting on borderlands and i will kill you all\",\n          \"so i spent a few hours making something for fun if you don t know i am a huge fan and maya is one of my favorite characters so i decided to make myself a wallpaper for my pc here is the original image versus the creation i made enjoy pic twitter com mlsi5wf9jg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Install / import dependencies ---\n",
        "!pip install --quiet gensim\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# --- Configurable parameters ---\n",
        "FALLBACK_CSV_PATH = \"/content/twitter_training.csv\"   # <- session file path (used if you don't upload)\n",
        "ARTIFACT_DIR = \"/content/feature_artifacts\"\n",
        "MAX_TFIDF_FEATURES = 5000\n",
        "W2V_VECTOR_SIZE = 100\n",
        "W2V_WINDOW = 5\n",
        "W2V_MIN_COUNT = 2\n",
        "W2V_EPOCHS = 10\n",
        "TOKENIZER_VOCAB_SIZE = 10000\n",
        "MAX_SEQ_LEN = 50   # padded sequence length\n",
        "\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "csv_fname = FALLBACK_CSV_PATH\n",
        "   # print(\"No uploaded file detected; using fallback path:\", csv_fname)\n",
        "\n",
        "df = pd.read_csv(csv_fname)\n",
        "print(\"Loaded data shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# --- Detect text column (common names or longest object column) ---\n",
        "text_candidates = [c for c in df.columns if c.lower() in (\"text\",\"tweet\",\"tweet_text\",\"content\",\"message\",\"tweettext\")]\n",
        "if text_candidates:\n",
        "    text_col = text_candidates[0]\n",
        "else:\n",
        "    obj_cols = [c for c in df.columns if df[c].dtype == object]\n",
        "    if not obj_cols:\n",
        "        raise ValueError(\"No string-like column found to use as text column.\")\n",
        "    lengths = {c: df[c].astype(str).str.len().mean() for c in obj_cols}\n",
        "    text_col = max(lengths, key=lengths.get)\n",
        "\n",
        "print(\"Selected text column:\", text_col)\n",
        "\n",
        "# --- Basic cleaning (if cleaned_text not already present) ---\n",
        "import re\n",
        "url_re = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "mention_re = re.compile(r'@\\w+')\n",
        "hashtag_re = re.compile(r'#\\w+')\n",
        "html_re = re.compile(r'<.*?>')\n",
        "special_re = re.compile(r'[^A-Za-z0-9\\s]')    # remove punctuation and many emojis\n",
        "multi_space_re = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = url_re.sub(' ', text)\n",
        "    text = mention_re.sub(' ', text)\n",
        "    text = hashtag_re.sub(' ', text)\n",
        "    text = html_re.sub(' ', text)\n",
        "    text = special_re.sub(' ', text)\n",
        "    text = text.lower()\n",
        "    text = multi_space_re.sub(' ', text).strip()\n",
        "    return text\n",
        "\n",
        "if 'cleaned_text' not in df.columns:\n",
        "    print(\"Applying cleaning to create 'cleaned_text' column...\")\n",
        "    df['cleaned_text'] = df[text_col].apply(clean_text)\n",
        "else:\n",
        "    print(\"'cleaned_text' already present  skipping raw cleaning step.\")\n",
        "\n",
        "# --- Tokenization + stopword removal + lemmatization ---\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize_and_lemmatize(text):\n",
        "    # basic whitespace tokenize (cleaned_text already lowercased)\n",
        "    toks = text.split()\n",
        "    out = []\n",
        "    for t in toks:\n",
        "        if t in stop_words:           # drop stopwords\n",
        "            continue\n",
        "        if t.isnumeric():             # drop pure numbers\n",
        "            continue\n",
        "        # lemma\n",
        "        t = lemmatizer.lemmatize(t)\n",
        "        if len(t) > 1:\n",
        "            out.append(t)\n",
        "    return out\n",
        "\n",
        "print(\"Tokenizing & lemmatizing...\")\n",
        "df['tokens'] = df['cleaned_text'].astype(str).apply(tokenize_and_lemmatize)\n",
        "# also produce a joined string column for vectorizers\n",
        "df['cleaned_joined'] = df['tokens'].apply(lambda toks: \" \".join(toks))\n",
        "\n",
        "print(\"Sample tokens:\")\n",
        "print(df[['cleaned_text','tokens']].head(4).to_dict(orient='records'))\n",
        "\n",
        "# --- 1) TF-IDF features ---\n",
        "print(\"\\n[TF-IDF] Fitting TfidfVectorizer (max_features=%d)...\" % MAX_TFIDF_FEATURES)\n",
        "tfidf = TfidfVectorizer(max_features=MAX_TFIDF_FEATURES)\n",
        "X_tfidf = tfidf.fit_transform(df['cleaned_joined'].values)\n",
        "print(\"TF-IDF shape:\", X_tfidf.shape)\n",
        "\n",
        "# Save TF-IDF vectorizer to disk (pickle)\n",
        "tfidf_path = os.path.join(ARTIFACT_DIR, \"tfidf_vectorizer.pkl\")\n",
        "with open(tfidf_path, \"wb\") as f:\n",
        "    pickle.dump(tfidf, f)\n",
        "print(\"Saved TF-IDF vectorizer to:\", tfidf_path)\n",
        "\n",
        "# --- 2) Word2Vec: train on tokens and build averaged tweet embeddings ---\n",
        "print(\"\\n[Word2Vec] Training Word2Vec (size=%d, window=%d, min_count=%d, epochs=%d) ...\" %\n",
        "      (W2V_VECTOR_SIZE, W2V_WINDOW, W2V_MIN_COUNT, W2V_EPOCHS))\n",
        "\n",
        "# Prepare sentences as list of token lists\n",
        "sentences = df['tokens'].tolist()\n",
        "w2v_model = Word2Vec(sentences=sentences,\n",
        "                     vector_size=W2V_VECTOR_SIZE,\n",
        "                     window=W2V_WINDOW,\n",
        "                     min_count=W2V_MIN_COUNT,\n",
        "                     workers=4,\n",
        "                     epochs=W2V_EPOCHS,\n",
        "                     sg=1)   # use skip-gram (sg=1)  change to sg=0 for CBOW\n",
        "\n",
        "print(\"Word2Vec vocab size:\", len(w2v_model.wv))\n",
        "\n",
        "# Create average embedding per tweet\n",
        "def average_embedding(tokens, model, vector_size):\n",
        "    vec = np.zeros(vector_size, dtype=np.float32)\n",
        "    n = 0\n",
        "    for t in tokens:\n",
        "        if t in model.wv:\n",
        "            vec += model.wv[t]\n",
        "            n += 1\n",
        "    if n > 0:\n",
        "        vec /= n\n",
        "    return vec\n",
        "\n",
        "print(\"Computing average Word2Vec embeddings for each tweet (this may take some time)...\")\n",
        "X_w2v = np.vstack([average_embedding(toks, w2v_model, W2V_VECTOR_SIZE) for toks in df['tokens'].tolist()])\n",
        "print(\"Word2Vec-averaged embedding matrix shape:\", X_w2v.shape)\n",
        "\n",
        "# Save Word2Vec model and averaged embeddings\n",
        "w2v_model_path = os.path.join(ARTIFACT_DIR, \"word2vec.model\")\n",
        "w2v_model.save(w2v_model_path)\n",
        "np.save(os.path.join(ARTIFACT_DIR, \"X_word2vec_avg.npy\"), X_w2v)\n",
        "print(\"Saved Word2Vec model to:\", w2v_model_path)\n",
        "print(\"Saved averaged embeddings to:\", os.path.join(ARTIFACT_DIR, \"X_word2vec_avg.npy\"))\n",
        "\n",
        "# --- 3) Keras Tokenizer -> sequences and padded arrays (for RNN/LSTM input) ---\n",
        "print(\"\\n[Keras Tokenizer] Fitting tokenizer (vocab_size=%d) and creating padded sequences (maxlen=%d)...\" %\n",
        "      (TOKENIZER_VOCAB_SIZE, MAX_SEQ_LEN))\n",
        "tokenizer = Tokenizer(num_words=TOKENIZER_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['cleaned_joined'].values)\n",
        "sequences = tokenizer.texts_to_sequences(df['cleaned_joined'].values)\n",
        "X_seq = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post', truncating='post')\n",
        "print(\"Sequences shape:\", X_seq.shape)\n",
        "print(\"Tokenizer num words (len word_index):\", len(tokenizer.word_index))\n",
        "\n",
        "# Save tokenizer (json) and padded sequences\n",
        "tokenizer_json_path = os.path.join(ARTIFACT_DIR, \"tokenizer.json\")\n",
        "with open(tokenizer_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(tokenizer.to_json())\n",
        "np.save(os.path.join(ARTIFACT_DIR, \"X_sequences_padded.npy\"), X_seq)\n",
        "print(\"Saved tokenizer to:\", tokenizer_json_path)\n",
        "print(\"Saved padded sequences to:\", os.path.join(ARTIFACT_DIR, \"X_sequences_padded.npy\"))\n",
        "\n",
        "# --- Optionally create embedding matrix for Keras using trained Word2Vec (to initialize Embedding layer) ---\n",
        "print(\"\\nBuilding embedding matrix for Keras Embedding layer from trained Word2Vec...\")\n",
        "vocab_size_used = min(TOKENIZER_VOCAB_SIZE, len(tokenizer.word_index) + 1)\n",
        "embedding_matrix = np.zeros((vocab_size_used, W2V_VECTOR_SIZE), dtype=np.float32)\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= vocab_size_used:\n",
        "        continue\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "# Save embedding matrix\n",
        "np.save(os.path.join(ARTIFACT_DIR, \"embedding_matrix.npy\"), embedding_matrix)\n",
        "print(\"Saved embedding matrix shape:\", embedding_matrix.shape, \"->\", os.path.join(ARTIFACT_DIR, \"embedding_matrix.npy\"))\n",
        "\n",
        "# --- Summary of outputs ---\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "print(\"TF-IDF matrix shape:\", X_tfidf.shape)\n",
        "print(\"Word2Vec averaged embeddings shape:\", X_w2v.shape)\n",
        "print(\"Padded sequences shape:\", X_seq.shape)\n",
        "print(\"Artifacts saved to:\", ARTIFACT_DIR)\n",
        "print(\"Files in artifact dir:\", os.listdir(ARTIFACT_DIR))\n"
      ],
      "metadata": {
        "id": "LoVsncRG3W7q",
        "outputId": "ea2b05f3-8255-4af9-bf03-08652dec562e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data shape: (74681, 4)\n",
            "Columns: ['2401', 'Borderlands', 'Positive', 'im getting on borderlands and i will murder you all ,']\n",
            "Selected text column: im getting on borderlands and i will murder you all ,\n",
            "Applying cleaning to create 'cleaned_text' column...\n",
            "Tokenizing & lemmatizing...\n",
            "Sample tokens:\n",
            "[{'cleaned_text': 'i am coming to the borders and i will kill you all', 'tokens': ['coming', 'border', 'kill']}, {'cleaned_text': 'im getting on borderlands and i will kill you all', 'tokens': ['im', 'getting', 'borderland', 'kill']}, {'cleaned_text': 'im coming on borderlands and i will murder you all', 'tokens': ['im', 'coming', 'borderland', 'murder']}, {'cleaned_text': 'im getting on borderlands 2 and i will murder you me all', 'tokens': ['im', 'getting', 'borderland', 'murder']}]\n",
            "\n",
            "[TF-IDF] Fitting TfidfVectorizer (max_features=5000)...\n",
            "TF-IDF shape: (74681, 5000)\n",
            "Saved TF-IDF vectorizer to: /content/feature_artifacts/tfidf_vectorizer.pkl\n",
            "\n",
            "[Word2Vec] Training Word2Vec (size=100, window=5, min_count=2, epochs=10) ...\n",
            "Word2Vec vocab size: 20861\n",
            "Computing average Word2Vec embeddings for each tweet (this may take some time)...\n",
            "Word2Vec-averaged embedding matrix shape: (74681, 100)\n",
            "Saved Word2Vec model to: /content/feature_artifacts/word2vec.model\n",
            "Saved averaged embeddings to: /content/feature_artifacts/X_word2vec_avg.npy\n",
            "\n",
            "[Keras Tokenizer] Fitting tokenizer (vocab_size=10000) and creating padded sequences (maxlen=50)...\n",
            "Sequences shape: (74681, 50)\n",
            "Tokenizer num words (len word_index): 27163\n",
            "Saved tokenizer to: /content/feature_artifacts/tokenizer.json\n",
            "Saved padded sequences to: /content/feature_artifacts/X_sequences_padded.npy\n",
            "\n",
            "Building embedding matrix for Keras Embedding layer from trained Word2Vec...\n",
            "Saved embedding matrix shape: (10000, 100) -> /content/feature_artifacts/embedding_matrix.npy\n",
            "\n",
            "=== SUMMARY ===\n",
            "TF-IDF matrix shape: (74681, 5000)\n",
            "Word2Vec averaged embeddings shape: (74681, 100)\n",
            "Padded sequences shape: (74681, 50)\n",
            "Artifacts saved to: /content/feature_artifacts\n",
            "Files in artifact dir: ['embedding_matrix.npy', 'X_word2vec_avg.npy', 'tokenizer.json', 'word2vec.model', 'tfidf_vectorizer.pkl', 'X_sequences_padded.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "csv_path = \"/content/twitter_training.csv\"   # change if you upload manually\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# ============================\n",
        "# 1. BASIC DATASET SUMMARY\n",
        "# ============================\n",
        "\n",
        "print(\"\\n===== DATASET INFO =====\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n===== NUMERIC SUMMARY (mean, median, std etc.) =====\")\n",
        "print(df.describe(include='all'))   # includes numeric + object info\n",
        "\n",
        "# ============================\n",
        "# 2. MEAN & MEDIAN (numeric only)\n",
        "# ============================\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "if len(numeric_cols) == 0:\n",
        "    print(\"\\nNo numeric columns found for mean/median.\")\n",
        "else:\n",
        "    print(\"\\n===== MEAN OF NUMERIC COLUMNS =====\")\n",
        "    print(df[numeric_cols].mean())\n",
        "\n",
        "    print(\"\\n===== MEDIAN OF NUMERIC COLUMNS =====\")\n",
        "    print(df[numeric_cols].median())\n",
        "\n",
        "# ============================\n",
        "# 3. MODE (most frequent values)\n",
        "# ============================\n",
        "print(\"\\n===== MODE (most frequent values per column) =====\")\n",
        "try:\n",
        "    print(df.mode().head(1))     # first most-common value\n",
        "except:\n",
        "    print(\"Mode calculation not available for some columns.\")\n",
        "\n",
        "# ============================\n",
        "# 4. MISSING VALUE SUMMARY\n",
        "# ============================\n",
        "print(\"\\n===== MISSING VALUES PER COLUMN =====\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "csv_path = \"/content/twitter_training.csv\"   # or replace with your upload\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Dataset loaded!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# ------------------------------------------\n",
        "# Detect sentiment column automatically\n",
        "# ------------------------------------------\n",
        "sentiment_candidates = [c for c in df.columns if c.lower() in\n",
        "                        (\"sentiment\", \"label\", \"class\", \"target\")]\n",
        "\n",
        "# If not found, search for common labels inside columns\n",
        "if not sentiment_candidates:\n",
        "    for col in df.columns:\n",
        "        values = df[col].astype(str).str.lower().unique()\n",
        "        if any(v in [\"positive\", \"negative\", \"neutral\", \"irrelevant\"] for v in values):\n",
        "            sentiment_candidates.append(col)\n",
        "\n",
        "if not sentiment_candidates:\n",
        "    raise ValueError(\" Could not detect sentiment column. Please specify manually.\")\n",
        "\n",
        "sentiment_col = sentiment_candidates[0]\n",
        "print(\"Detected sentiment column:\", sentiment_col)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Sentiment distribution\n",
        "# ------------------------------------------\n",
        "sent_counts = df[sentiment_col].value_counts()\n",
        "print(\"\\n===== SENTIMENT DISTRIBUTION =====\")\n",
        "print(sent_counts)\n",
        "\n",
        "# ------------------------------------------\n",
        "# Bar chart\n",
        "# ------------------------------------------\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=df[sentiment_col], order=sent_counts.index)\n",
        "plt.title(\"Sentiment Distribution\")\n",
        "plt.xlabel(\"Sentiment Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5ivIIcpL8IZJ",
        "outputId": "7043d9fd-d7f3-4370-adaf-35c789e351a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "Shape: (74681, 4)\n",
            "Columns: ['2401', 'Borderlands', 'Positive', 'im getting on borderlands and i will murder you all ,']\n",
            "\n",
            "===== DATASET INFO =====\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74681 entries, 0 to 74680\n",
            "Data columns (total 4 columns):\n",
            " #   Column                                                 Non-Null Count  Dtype \n",
            "---  ------                                                 --------------  ----- \n",
            " 0   2401                                                   74681 non-null  int64 \n",
            " 1   Borderlands                                            74681 non-null  object\n",
            " 2   Positive                                               74681 non-null  object\n",
            " 3   im getting on borderlands and i will murder you all ,  73995 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 2.3+ MB\n",
            "\n",
            "===== NUMERIC SUMMARY (mean, median, std etc.) =====\n",
            "                2401 Borderlands  Positive  \\\n",
            "count   74681.000000       74681     74681   \n",
            "unique           NaN          32         4   \n",
            "top              NaN   Microsoft  Negative   \n",
            "freq             NaN        2400     22542   \n",
            "mean     6432.640149         NaN       NaN   \n",
            "std      3740.423819         NaN       NaN   \n",
            "min         1.000000         NaN       NaN   \n",
            "25%      3195.000000         NaN       NaN   \n",
            "50%      6422.000000         NaN       NaN   \n",
            "75%      9601.000000         NaN       NaN   \n",
            "max     13200.000000         NaN       NaN   \n",
            "\n",
            "       im getting on borderlands and i will murder you all ,  \n",
            "count                                               73995     \n",
            "unique                                              69490     \n",
            "top                                                           \n",
            "freq                                                  172     \n",
            "mean                                                  NaN     \n",
            "std                                                   NaN     \n",
            "min                                                   NaN     \n",
            "25%                                                   NaN     \n",
            "50%                                                   NaN     \n",
            "75%                                                   NaN     \n",
            "max                                                   NaN     \n",
            "\n",
            "===== MEAN OF NUMERIC COLUMNS =====\n",
            "2401    6432.640149\n",
            "dtype: float64\n",
            "\n",
            "===== MEDIAN OF NUMERIC COLUMNS =====\n",
            "2401    6422.0\n",
            "dtype: float64\n",
            "\n",
            "===== MODE (most frequent values per column) =====\n",
            "   2401 Borderlands  Positive  \\\n",
            "0     1   MaddenNFL  Negative   \n",
            "\n",
            "  im getting on borderlands and i will murder you all ,  \n",
            "0                                                        \n",
            "\n",
            "===== MISSING VALUES PER COLUMN =====\n",
            "2401                                                       0\n",
            "Borderlands                                                0\n",
            "Positive                                                   0\n",
            "im getting on borderlands and i will murder you all ,    686\n",
            "dtype: int64\n",
            "Dataset loaded!\n",
            "Shape: (74681, 4)\n",
            "Columns: ['2401', 'Borderlands', 'Positive', 'im getting on borderlands and i will murder you all ,']\n",
            "Detected sentiment column: Positive\n",
            "\n",
            "===== SENTIMENT DISTRIBUTION =====\n",
            "Positive\n",
            "Negative      22542\n",
            "Positive      20831\n",
            "Neutral       18318\n",
            "Irrelevant    12990\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}